{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Python and Pandas\n",
    "\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "1. [Introduction](#introduction)<br>\n",
    "1.1. [Series and DataFrames](#series)<br>\n",
    "1.2. [Indexing](#index)<br>\n",
    "1.3. [Data Selection](#selection)<br>\n",
    "2. [Transform data](#transform)<br>\n",
    "2.1. [Adding and deleting columns](#columns)<br>\n",
    "2.2. [Cleaning Data](#cleaning)<br>\n",
    "2.3. [Merging Data](#merging)<br>\n",
    "2.4. [Grouping Data](#grouping)<br>\n",
    "3. [Visualise data](#visualise)<br>\n",
    "4. [Optional Excercises and further learning](#extra)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with loading the packages and a quick look at some data. Select the below cell by clicking on it, and then click on the `Run` button at the top of the notebook (or use `Shift+Enter`). This is how you can run all code cells in this notebook. The numbers in front of the cells tell you in which order you have run them, for instance `[1]`. When you see a `[*]` the cell is currently running and `[]` means you have not run the cell yet. **It is important to run all cells!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the first cell with code above, restart the notebook by clicking on the `Kernel` tab at the top of the notebook, and then `Restart`. You do not have to run the above cell again after the restart as updating the seaborn package only has to be done once. It is best to do this now instead of finding out later in the notebook that this package is out of date.\n",
    "\n",
    "Now run the next cell that will import two other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas it is easy to load a csv file. Let's load a file by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/london-borough-profiles.csv',encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"font-size:100%\">\n",
    "If you are using <b>Watson Studio</b> to run the workshop you will get an error with the above, because you have no local files in the data folder. First store the data in your Cloud Object Store (COS) by adding the files in the menu on the right of the notebook (if you see no menu, click the <b><font face=\"Courier\">1010</font></b> button at the top first) and then load the data by following these steps:\n",
    "\n",
    "\n",
    "\n",
    "<ul>\n",
    "  <li>Activate the below cell, move the cursor to the empty line under  <b><font face=\"Courier\"># add data</font></b></li>\n",
    "  <li>Click on <b><font face=\"Courier\">Insert to code</font></b> under the file from the right menu</li>\n",
    "  <li>Select <b><font face=\"Courier\">Insert pandas DataFrame</font></b></li>\n",
    "  <li>Code to load the file will be inserted</li>\n",
    "  <li>Change the default name of the data from <b><font face=\"Courier\">df_data_1</font></b> to <b><font face=\"Courier\">df</font></b> at the bottom two lines of the inserted code and add <b><font face=\"Courier\">encoding = 'unicode_escape'</font></b> after <b><font face=\"Courier\">body,</font></b> </li>\n",
    "    <li>Then run the cell to load the data</li>\n",
    "   </ul> \n",
    "   \n",
    "  <ul></ul>\n",
    "   <ul></ul>\n",
    "   \n",
    "  <i>  The Dataset 'london-borough-profiles.csv' used in this notebook was acquired from <a href=\"https://data.gov.uk/dataset/248f5f04-23cf-4470-9216-0d0be9b877a8/london-borough-profiles-and-atlas\">london-borough-profiles</a>   <i>\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b> <br/> \n",
    " Now let's have a look at the data that was loaded into the notebook. What are we actually looking at? Use for instance df, df.head() or df.tail() to see different parts of the table and jeans.dtypes to check which variables there are and what datatype they have. Add a number between the emply brackets () to specify how many lines you want to display.\n",
    "    \n",
    "  Explore some of the following commands:\n",
    "  <ul>\n",
    "  <li><font face=\"Courier\">df.head()</font></li>\n",
    "  <li><font face=\"Courier\">df.tail()</font></li>\n",
    "  <li><font face=\"Courier\">df.columns</font></li>\n",
    "  <li><font face=\"Courier\">df.values</font></li>\n",
    "  <li><font face=\"Courier\">len(df)</font></li>\n",
    "  <li><font face=\"Courier\">list(df)</font></li>\n",
    "  </ul>\n",
    "</div>  \n",
    "\n",
    "> *Tip*: If you want to run these in separate cells, activate the below cell by clicking on it and then click on the + at the top of the notebook. This will add extra cells. Click on the buttons with the upwards and downwards arrows to move the cells up and down to change their order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the commands here (add as many cells as you need):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## 1. Introduction\n",
    "\n",
    "The Python package you used to read this file and look at some of it's properties is [Pandas](https://pandas.pydata.org/), which is an open source library with easy-to-use data structures and data analysis tools. \n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "<b>Read this <a href=\"http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\">10 minute introduction</a> for a quick overview of Pandas.<br>\n",
    "</div>\n",
    "\n",
    "<a id=\"series\"></a>\n",
    "### 1.1 Series and DataFrames \n",
    "\n",
    "Let's go through some of the basics of Pandas before going back to the London dataset. Pandas has two main data structures: `Series` and `DataFrames`. \n",
    "\n",
    "A `Series` is a list of values with an integer index. The first column is the index (the default starts at 0) and the second column the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A `DataFrame` is similar, but has multiple columns. You can create one in many ways, by loading a file or from for example a NumPy array and a date for the index. (We come back to the index and dates later) \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "<b>Read this <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html\"> tutorial</a> for an overview of NumPy.<br>\n",
    "</div>\n",
    "\n",
    "Two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.random.randn(6, 4)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(numbers, index=dates, columns=list('ABCD'))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                     'B': pd.Timestamp('20130102'),\n",
    "                     'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                     'D': np.array([3] * 4, dtype='int32'),\n",
    "                     'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                     'F': 'foo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out what the data type is of a variable use `type()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data type of s is '+str(type(s)))\n",
    "print('Data type of s is '+str(type(dates)))\n",
    "print('Data type of s is '+str(type(numbers)))\n",
    "print('Data type of df is '+str(type(df1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "### 1.2 Indexing \n",
    "\n",
    "It is important to understand the `index` to work with dataframes, so let's explore this a little. We will com back to it more later. \n",
    "\n",
    "For this we will make a copy of the `df` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = boroughs.set_index('Area_name')\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = boroughs.reset_index()\n",
    "boroughs = boroughs.set_index(['Area_name','Inner/_Outer_London'])\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = boroughs.reset_index()\n",
    "boroughs = boroughs.set_index(['Area_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"selection\"></a>\n",
    "### 1.3 Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a single label or a range of labels with `.loc[]` (This only works for the column that was set to the index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.loc['City of London', 'Inland_Area_(Hectares)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.loc['City of London':'Bexley', ['Inland_Area_(Hectares)', 'Average_Age,_2017']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or select by position with `.iloc[]`. You can select a single row, multiple rows (or columns) at particular positions in the index, it only takes integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.iloc[2:4,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use one or more column names to create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Inland_Area_(Hectares)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs2 = boroughs[['Inland_Area_(Hectares)', 'Average_Age,_2017']]\n",
    "boroughs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "\n",
    "Selecting rows based on a certain condition can be done with Boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs['Average_Age,_2017'] > 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select the data add `boroughs[]` around the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs[boroughs['Average_Age,_2017'] > 38]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining different columns using `&`, `|` and `==` is also possible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs[(boroughs['Average_Age,_2017'] > 38) & (boroughs['GLA_Population_Estimate_2017'] > 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs[(boroughs['Average_Age,_2017'] < 38) | (boroughs['GLA_Population_Estimate_2017'] < 1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs[boroughs['Average_Age,_2017'] == 40.2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b> <br/> \n",
    " With the above commands you can now start exploring the data some more. Answer some of the following questions by writing a little code (add as many cells as you need):\n",
    "  <ul>\n",
    "  <li>Which Area has the largest Density per hectare in 2017? </li>  \n",
    "  <li>Maximum and Minimum number of New Migrants in 2015/2016</li>   \n",
    "  <li> Extract the entire row for the borough with the highest happiness score </li>\n",
    "  <li> Which Area has the third largest population by county of birth in 2011 as 'Romania' </li>\n",
    "  \n",
    " </ul>  \n",
    "</div>  \n",
    "\n",
    "\n",
    "> *Tips*: \n",
    "- Find the maximum of a row with for instance `boroughs['Population'].max()` \n",
    "- Extract the value from a cell in a DataFrame with `.value[]`\n",
    "- Print a value with `print()` for instance: `print(boroughs['area'][0])` for the first row. If you calculate multiple values in one cell you will need this, else the answers will not be displayed.\n",
    "- To extract an entire row use `idxmax()` which returns column with maximum value, and `.loc[]` to return row of the index\n",
    "- To see the answer uncomment the line in the cell that contains `%load` (by deleting the `#`) and then run the cell, but try to find your own solution first in the cell above the solution!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transform\"></a>\n",
    "## 2. Transform Data\n",
    "\n",
    "When looking at data there are always transformations needed to get it in the format you need for your analysis, visualisations or models. \n",
    "\n",
    "These are a few examples of the endless possibilities. The best way to learn is to find a dataset and try to answer questions with the data. The Pandas documentation is real good, and on StackOverflow there is almost always someone who asked the same question already. \n",
    "\n",
    "<a id=\"columns\"></a>\n",
    "### 2.1 Adding and deleting columns\n",
    "Adding a column can be done by defining a new column, which can then be dropped with 'drop'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['new'] = 1\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = boroughs.drop(columns='new')\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['House Size'] = boroughs['Inland_Area_(Hectares)'] / boroughs['GLA_Population_Estimate_2017']\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "### 2.2 Cleaning Data\n",
    "\n",
    "Things to check:\n",
    "\n",
    "- Is the data tidy: each variable forms a column, each observation forms a row and  each type of observational unit forms a table.\n",
    "- Are all columns in the right data format?\n",
    "- Are there missing values?\n",
    "- Are there unrealistic outliers?\n",
    "\n",
    "Get a quick overview of the numeric data with `.describe()`. If any of the numeric columns is missing this is a probably because of a wring data type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Renaming\"></a>\n",
    "### 2.2 Renaming Columns\n",
    "\n",
    "You can change names of columns using the rename function. One of the biggest advantages of using rename function is that we can use rename to change as many column names as we want. \n",
    "\n",
    "Ex : \n",
    "DataFrame.rename(columns={'Coun':'Country',\n",
    "                          'Emp':'Employment',\n",
    "                           'Cont' : 'Continent'}, \n",
    "                          \n",
    "In the below we are changing the name of a single column. We are also going to use inplace=True to change column names in place. \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.rename(columns={'%_of_largest_migrant_population_(2011)':'largest_migrant_population_2011(%)'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the print function to check if the column name has changed as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boroughs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the rename funtion to change row indexes or row names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.rename(index={0:'zero',1:'one'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not always ideal to have text in the table. Especially not if you want to create a model from the data. It is better to transform the data with `get.dummies()`. The below will add 4 new columns to the DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boroughs2 = boroughs.copy()\n",
    "Code = pd.get_dummies(boroughs2['Code'], drop_first=True)\n",
    "boroughs2 = boroughs2.join(Code)\n",
    "boroughs2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or do this all in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = boroughs.join(pd.get_dummies(boroughs['Code'], drop_first=True))\n",
    "boroughs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merging\"></a>\n",
    "### 2.3 Merging Data\n",
    "\n",
    "There are several ways to combine data. The [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) has lots of examples. You can combine data with `.append()` or `.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'city':       ['London','Manchester','Birmingham','Leeds','Glasgow'],\n",
    "        'population': [9787426,  2553379,     2440986,    1777934,1209143],\n",
    "        'area':       [1737.9,   630.3,       598.9,      487.8,  368.5 ]}\n",
    "cities = pd.DataFrame(data)\n",
    "\n",
    "data2 = {'city':       ['Liverpool','Southampton'],\n",
    "        'population': [864122,  855569],\n",
    "        'area':       [199.6,   192.0]}\n",
    "cities2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These new cities can be added with `append()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.append(cities2)\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'city': ['London','Manchester','Birmingham','Leeds','Glasgow'],\n",
    "        'density': [5630,4051,4076,3645,3390]}\n",
    "cities3 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extra column can be added with `.merge()` with an outer join using the city names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.merge(cities, cities3, how='outer', sort=True,on='city')\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that does not quite fit can be merged as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'city':       ['Newcastle','Nottingham'],\n",
    "        'population': [774891,  729977],\n",
    "        'area':       [180.5,   176.4]}\n",
    "\n",
    "cities4 = pd.DataFrame(data)\n",
    "cities4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.append(cities4)\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"grouping\"></a>\n",
    "### 2.4 Grouping Data\n",
    "\n",
    "Grouping data is a quick way to calculate values for classes in your DataFrame. The example below gives you the mean values of all variables for `Inner/Outer London`, and for a combination of all classes when `Area name` and `Resident Population born abroad` are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.columns\n",
    "boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.groupby(['Inner/_Outer_London']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs.groupby(['Area_name','%_of_resident_population_born_abroad_(2015)']).max().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore\"></a>\n",
    "## 3. Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without this the plots would be opened  in a new window (not browser)\n",
    "# with this instruction plots will be included in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we reset the Index to Area Name earlier in the notebook, We would need to reset it again to be able to use the Area Names in our maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = boroughs.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default plot is a line chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Employment_rate_(%)_(2015)'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a plot that makes more sense for this data have a look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) for all options. A histogram might work better. Go ahead and change the number of bins until you think the number of bins looks right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Employment_rate_(%)_(2015)'].plot.hist(bins=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the size of the plot with `figsize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Employment_rate_(%)_(2015)'].plot.hist(bins=15,figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select data as you learned earlier, direclty in a plot command. The below plot shows the Employment Rate only in Outer London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Employment_rate_(%)_(2015)'][boroughs['Inner/_Outer_London']=='Outer London'].plot.hist(bins=15,figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the Employment Rate for Inner London as well, simply repeat the plot command with a different selection of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Employment_rate_(%)_(2015)'][boroughs['Inner/_Outer_London']=='Outer London'].plot.hist(bins=15,figsize=(10,5));\n",
    "boroughs['Employment_rate_(%)_(2015)'][boroughs['Inner/_Outer_London']=='Inner London'].plot.hist(bins=15,figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is difficult to read as the histograms overlap. You can fix this by changing the colours and making them transparant. To add a legend each histogram needs to be assigned to an object `ax` that is used to create a legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = boroughs['Employment_rate_(%)_(2015)'][boroughs['Inner/_Outer_London']=='Outer London'].plot.hist(\n",
    "    bins=15,figsize=(10,5),alpha=0.5,color='#1A4D3B');\n",
    "ax = boroughs['Employment_rate_(%)_(2015)'][boroughs['Inner/_Outer_London']=='Inner London'].plot.hist(\n",
    "    bins=15,figsize=(10,5),alpha=0.5,color='#4D1A39');\n",
    "ax.legend(['Inner London','Outer London']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to change pretty much everything as in the below code. This was the ugliest I could come up with. Can you make it worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs['Population_density_(per_hectare)_2017'].plot.hist(\n",
    "    bins=15, \n",
    "    title=\"Population Density\",\n",
    "    legend=False,\n",
    "    fontsize=14,\n",
    "    grid=False,\n",
    "    linestyle='--',\n",
    "    edgecolor='black',\n",
    "    color='darkred',\n",
    "    linewidth=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "Seaborn is an easy to use visualisation package that works well with Pandas DataFrames. Below are a few examples, but have a look at the [documentation](https://seaborn.pydata.org/index.html) as there are many more plots you could make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(boroughs['Population_density_(per_hectare)_2017'].dropna());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Turnout_at_2014_local_elections', y='Political_control_in_council', data=boroughs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Median_House_Price,_2015', y='Area_name', kind='swarm', data=boroughs, );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Employment_rate_(%)_(2015)\", y=\"Largest_migrant_population_by_country_of_birth_(2011)\", kind=\"box\", data=boroughs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fig, ax] = plt.subplots(1, figsize=(6,6))\n",
    "ax=sns.scatterplot(y='Area_name', x='Political_control_in_council', data=boroughs, ax=ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    " <b>EXERCISE</b>\n",
    " <ul>\n",
    "  <li>Create two histograms that compare the Gross Annual pay for Male and Female Employees using `.plot.hist()`</li>\n",
    "  <li>Create a bar plot comparing the median house prices for different Areas using a barplot</li>\n",
    "  <li>Create a scatter plot comparing the Median House price and percentage of area that is greenspace </li>\n",
    "  <li>Create a box plot showing the youth unemployment rate among the largest migrant population arrived during year 15-16 </li>\n",
    "  <li>Explore the data further by creating more plots that can aswer questions that you have about the dataset</li>\n",
    " </ul> \n",
    "   </div> \n",
    "   \n",
    " <ul></ul> \n",
    " <ul></ul> \n",
    " <ul></ul> \n",
    " \n",
    " > *Tips*:\n",
    "-  Tip: to add two histograms to one plot you can repeat `.plot()` in the same cell \n",
    "-  Add a Legend by assiging each Histogram to an object `ax` which is used to create a legend\n",
    "-  Tip: For a box plot in Seaborn, use `catplot` where kind = `box` \n",
    "-  To customise the size of your maps, use the example of `[fig, ax]` which customises the figsize for each map in other examples above \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer5.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer6.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer7.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/IBMDeveloperUK/foss4g-geopandas/master/answers/pandas_answer8.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"extra\"></a>\n",
    "# 4. Optional Excercises and further learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you finish early:\n",
    "\n",
    "2. Try to create other plots. Have a look at the [Pandas plot examples](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) or the [Seaborn gallery](https://seaborn.pydata.org/examples/index.html) for inspiration.  \n",
    "3. Or load one of your own datasets into a new notebook and play around with the data to practice what you have learned. You can use the free account you created today for your own projects as well! \n",
    "4. Have a look at these Pandas workshops and book: <br>\n",
    "4.1. [Pandas workshop by Alexander Hensdorf](https://github.com/alanderex/pydata-pandas-workshop) <br>\n",
    "4.2. [Pandas tutorial by Joris van den Bossche](https://github.com/jorisvandenbossche/pandas-tutorial) <br>\n",
    "4.3. [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "Margriet Groenendijk is a Data & AI Developer Advocate for IBM. She develops and presents talks and workshops about data science and AI. She is active in the local developer communities through attending, presenting and organising meetups. She has a background in climate science where she explored large observational datasets of carbon uptake by forests during her PhD, and global scale weather and climate models as a postdoctoral fellow. \n",
    "\n",
    "Yamini Rao is a Developer Advocate for IBM. She compiles Developer scenarios, workshops and training material based on IBM Cloud technologies to demonstrate value. She also works as a community manager, collaborating with local developer communites to organise workshops and meetups. She has a background in computer science and has worked extensively as an Implementation Engineer for various IBM Analytical tools. \n",
    "\n",
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
