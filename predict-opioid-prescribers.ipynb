{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict opioid prescribers with scikit-learn\n",
    "\n",
    "Based on this [notebook](https://github.com/IBM/predict-opioid-prescribers) by Madison Myers\n",
    "\n",
    "\n",
    "## Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 3 datasets into the notebook by using the `Insert to code` button below for each file from the *Files* menu on the right and then click `Insert Pandas DataFrame`. Make sure that they are named correctly as these will be used the rest of the notebook:\n",
    "\n",
    "- 'df_data_1': opioids.csv\n",
    "- 'df_data_2': overdoses.csv\n",
    "- 'df_data_3': prescriber-info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert file 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert file 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert file 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by removing the `,` from the numbers in the `Deaths` and `Population` columns so that they can be used as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_2['Deaths'] = df_data_2['Deaths'].str.replace(',', '')\n",
    "df_data_2['Deaths'] = df_data_2['Deaths'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_2['Population'] = df_data_2['Population'].str.replace(',', '')\n",
    "df_data_2['Population'] = df_data_2['Population'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional column with the deaths per capita `Deaths/Population` for each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_2['Deaths/Population'] = (df_data_2['Deaths']/df_data_2['Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pixiedust to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many opioid deaths by U.S. state?\n",
    "\n",
    "With PixieDust data can be easily displayed. Have a play and change the chart type and change the settings on the right of the chart (if you get an error just try another option). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "barChart",
      "keyFields": "State",
      "orientation": "horizontal",
      "rendererId": "matplotlib",
      "rowCount": "500",
      "valueFields": "Deaths"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It definitely looks like California has a great deal more deaths than any other state. But California is a huge state with a matching population. Because of this we need to take a look at the values of deaths per capita.\n",
    "\n",
    "### What about deaths (% of population) by U.S. State?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "barChart",
      "keyFields": "State",
      "orientation": "horizontal",
      "rendererId": "matplotlib",
      "rowCount": "500",
      "valueFields": "Deaths/Population"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "West Virginia, New Mexico, New Hampshire, Ohio, Kentucky and Delaware stand out. \n",
    "\n",
    "Let's check this out with a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "googlemapapikey": " AIzaSyDi-BV6kv6RzFOB8-F8454uvk1tzYseFVg ",
      "handlerId": "mapView",
      "keyFields": "State",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA",
      "rendererId": "google",
      "rowCount": "500",
      "title": "Deaths per Capita by Opioid Overdoses",
      "valueFields": "Deaths/Population"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to exploring the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large number of prescriptions with their physicians' gender, state, speciality, whether they are an opioid prescriber or not and unique ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the states. Why are there more than 50 states?\n",
    "df_data_3.State.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare to df_data_2.\n",
    "df_data_2.Abbrev.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up states and make the dataset state list equal.\n",
    "#I checked the list of US state abbreviations and did not recognize PR, AE, ZZ, GU, AA or VI. After checking I learned that PR is Puerto Rico, GU is Guam and VI is Virgin Islands.\n",
    "#Though I identified 3 of the 6 unknowns, I'll remove all of them as dataset 2 does not have data regarding PR, GU or VI.\n",
    "df_data_3 = df_data_3[df_data_3.State != 'AE']\n",
    "df_data_3 = df_data_3[df_data_3.State != 'ZZ']\n",
    "df_data_3 = df_data_3[df_data_3.State != 'AA']\n",
    "df_data_3 = df_data_3[df_data_3.State != 'PR']\n",
    "df_data_3 = df_data_3[df_data_3.State != 'GU']\n",
    "df_data_3 = df_data_3[df_data_3.State != 'VI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure it worked!\n",
    "df_data_3.State.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many credentials there are.\n",
    "df_data_3.Credentials.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out the specialties.\n",
    "df_data_3.Specialty.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How much of the dataset is male vs female?\n",
    "df_data_3.groupby('Gender').size() / df_data_3.groupby('Gender').size().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the percentage of prescribers in our dataset that prescribe opioid drugs vs that do not?\n",
    "df_data_3.groupby('Opioid.Prescriber').size() / df_data_3.groupby('Opioid.Prescriber').size().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the opioid prescriber count vs non opioid prescriber count.\n",
    "#The dataset has a slightly higher number of opioid prescribers.\n",
    "pd.value_counts(df_data_3['Opioid.Prescriber']).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Classifiers to Predict Opioid Prescribers\n",
    "\n",
    "Can we predict who prescribed opioids based on this data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of Approaches: Kaggle and Indiana University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - \"Quick and Dirty\" approach from Kaggle (https://www.kaggle.com/jiashenliu/quick-and-dirty-attempt-on-voting-classifier)\n",
    " - \"Detecting Frequent Opioid Prescription\" (https://inclass.kaggle.com/apryor6/detecting-frequent-opioid-prescription)\n",
    " - Indiana University: \"Opiate prescription analysis using machine learning\" (http://cgi.soic.indiana.edu/~arunsank/AML_report.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the shape of the data frame to set up our classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Mark opioid vs non opiod drugs in df_data_3 with use of the data in df_data_1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opioids = df_data_1 \n",
    "name=opioids['Drug Name']\n",
    "import re\n",
    "new_name=name.apply(lambda x:re.sub(\"\\ |-\",\".\",str(x)))\n",
    "columns=df_data_3.columns\n",
    "Abandoned_variables = set(columns).intersection(set(new_name))\n",
    "Kept_variable=[]\n",
    "for each in columns:\n",
    "    if each in Abandoned_variables:\n",
    "        pass\n",
    "    else:\n",
    "        Kept_variable.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the new shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_data_3[Kept_variable]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remove the Credentials and NPI column to trim the features down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[[0, 3]], axis=1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,test_size=0.2,random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_columns=['Gender','State','Specialty']\n",
    "\n",
    "for col in Categorical_columns:\n",
    "    train[col]=pd.factorize(train[col], sort=True)[0]\n",
    "    test[col] =pd.factorize(test[col],sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=train.iloc[:,1:242] #make sure we only use the columns that we want as our features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models. Use several classifiers to check which one has the highest accuracy.\n",
    "\n",
    "Some are commented out as they take a bit too long to run for this lab. Be patient as it will take a couple of minutes to optimize the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=train.iloc[:,0:242] #Make sure to remove Opioid.Prescriber (the target)!\n",
    "target = train['Opioid.Prescriber']\n",
    "Name=[]\n",
    "Accuracy=[]\n",
    "model1=LogisticRegression(random_state=22,C=0.000000001,solver='liblinear',max_iter=200)\n",
    "model2=GaussianNB()\n",
    "model3=RandomForestClassifier(n_estimators=200,random_state=22)\n",
    "model4=GradientBoostingClassifier(n_estimators=200)\n",
    "model5=KNeighborsClassifier()\n",
    "model6=DecisionTreeClassifier()\n",
    "model7=LinearDiscriminantAnalysis()\n",
    "Ensembled_model=VotingClassifier(estimators=[('lr', model1), ('gn', model2), ('rf', model3),('gb',model4),('kn',model5),('dt',model6),('lda',model7)], voting='hard')\n",
    "#for model, label in zip([model1, model2, model3, model4,model5,model6,model7], ['Logistic Regression','Naive Bayes','Random Forest', 'Gradient Boosting','KNN','Decision Tree','LDA']):\n",
    "for model, label in zip([model1, model3, model4 ,model6], ['Logistic Regression','Random Forest', 'Gradient Boosting','Decision Tree']):\n",
    "    scores = cross_val_score(model, features, target, cv=5, scoring='accuracy')\n",
    "    Accuracy.append(scores.mean())\n",
    "    Name.append(model.__class__.__name__)\n",
    "    print(\"Accuracy: %f of model %s\" % (scores.mean(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3, 4 and 6 perform best. Let's predict the opioids prescriber for each of them with the test data with `fit()` and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "classifers=[model3,model4,model6]\n",
    "out_sample_accuracy=[]\n",
    "Name_2=[]\n",
    "for each in classifers:\n",
    "    fit=each.fit(features,target)\n",
    "    pred=fit.predict(test.iloc[:,0:242])\n",
    "    accuracy=accuracy_score(test['Opioid.Prescriber'],pred)\n",
    "    Name_2.append(each.__class__.__name__)\n",
    "    out_sample_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sample_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The confusion matrix\n",
    "\n",
    "You can read this when you keep in mind that the true label is on the 'y-axis' and the predicted label on the 'x-axis'. This means the top left and lower left are the numbers that are predicted correctly, and the bottom left and top right are predicted wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_actu = test['Opioid.Prescriber']\n",
    "confusion_matrix(y_actu, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After running various classifiers, we find that Random Forest and Gradient Boostinghad the best performance comparatively. This means that if we were to build a larger project, we could focus on these particular classifiers, building upon them to help predict opioid prescribers (given more years of data). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
